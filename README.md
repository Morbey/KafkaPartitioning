# Kafka Partitions PoC - Modern Setup without Zookeeper

Este projeto demonstra uma aplica√ß√£o completa de Kafka usando Spring Kafka (sem Spring Cloud Stream), com persist√™ncia em PostgreSQL/Oracle usando Hibernate 6, padr√£o Transactional Outbox, **agrega√ß√£o de snapshots por task**, e monitoriza√ß√£o com Prometheus e Grafana.

## üéØ Caracter√≠sticas Principais

- ‚úÖ **Kafka em modo KRaft** - Sem depend√™ncia de Zookeeper
- ‚úÖ **Persist√™ncia completa** - PostgreSQL com Hibernate 6
- ‚úÖ **Suporte Oracle** - Outbox em Oracle Database com polling JDBC ou Oracle AQ/JMS
- ‚úÖ **Padr√£o Outbox** - Produ√ß√£o transacional de mensagens
- ‚úÖ **Agrega√ß√£o por Task** - Snapshots completos em vez de mensagens por atributo
- ‚úÖ **Read-Model materializado** - Tabela `task_snapshots` para consulta eficiente
- ‚úÖ **Hierarquia de dados** - Task ‚Üí TaskAttribute ‚Üí TaskAttributeValue
- ‚úÖ **Processamento simulado** - Delay configur√°vel (2-20 segundos)
- ‚úÖ **Preven√ß√£o de rebalances** - Configura√ß√µes otimizadas para processamento longo
- ‚úÖ **Graceful shutdown** - Endpoint para parar consumo antes de terminar o pod
- ‚úÖ **Monitoriza√ß√£o** - Prometheus + Grafana com m√©tricas personalizadas
- ‚úÖ **Testes de integra√ß√£o** - Testcontainers com Kafka e PostgreSQL
- ‚úÖ **Distribui√ß√£o por parti√ß√µes** - Mensagens distribu√≠das por key (cliente)
- ‚úÖ **Multi-ambiente** - Suporte para Docker local, PostgreSQL empresarial e Oracle Database
- ‚úÖ **Perfil padr√£o empresarial** - Configurado para usar servi√ßos externos sem Docker

## üìã Estrutura do Projeto

```
kafkaPartitionsPoc/
‚îú‚îÄ‚îÄ consumer-app/          # Aplica√ß√£o consumidora com persist√™ncia
‚îÇ   ‚îú‚îÄ‚îÄ entity/           # Task, TaskAttribute, TaskAttributeValue, MessageRecord
‚îÇ   ‚îú‚îÄ‚îÄ repository/       # Spring Data JPA repositories
‚îÇ   ‚îú‚îÄ‚îÄ service/          # TaskConsumerService com processamento 2-20s
‚îÇ   ‚îú‚îÄ‚îÄ config/           # Kafka consumer config com rebalance prevention
‚îÇ   ‚îî‚îÄ‚îÄ controller/       # Endpoint /internal/stop-consuming
‚îú‚îÄ‚îÄ producer-app/          # Aplica√ß√£o produtora com Outbox pattern
‚îÇ   ‚îú‚îÄ‚îÄ entity/           # OutboxMessage
‚îÇ   ‚îú‚îÄ‚îÄ repository/       # OutboxMessageRepository
‚îÇ   ‚îú‚îÄ‚îÄ service/          # OutboxPollingService (scheduler)
‚îÇ   ‚îú‚îÄ‚îÄ controller/       # REST API para adicionar mensagens ao outbox
‚îÇ   ‚îî‚îÄ‚îÄ config/           # Kafka producer config
‚îú‚îÄ‚îÄ monitoring/            # Configura√ß√µes Prometheus + Grafana
‚îî‚îÄ‚îÄ docker-compose.yml     # Kafka (KRaft), PostgreSQL, Prometheus, Grafana
```

## üöÄ Quick Start

### Pr√©-requisitos

- Java 17+
- Maven 3.6+
- Docker e Docker Compose (para ambiente local)
- **OU** acesso a Kafka e PostgreSQL externos (ambiente empresarial)

### Escolher o Perfil de Execu√ß√£o

Este projeto suporta tr√™s perfis de execu√ß√£o:

#### 1. **Perfil `local`** (padr√£o) - Ambiente Empresarial (sem Docker)
Usa Kafka e PostgreSQL externos configurados via vari√°veis de ambiente.
**Este √© o perfil padr√£o** - ideal para ambientes empresariais profissionais.

#### 2. **Perfil `docker`** - Ambiente Local com Docker
Usa Kafka e PostgreSQL levantados localmente via `docker-compose`.
Use este perfil apenas quando explicitamente solicitado para desenvolvimento local.

#### 3. **Perfil `oracle`** - Ambiente com Oracle Database
Usa Oracle Database para a tabela de outbox, com Kafka externo.
Ideal para ambientes onde Oracle AQ/JMS j√° est√° em uso.

### 1. Iniciar Infraestrutura

#### Op√ß√£o A: Ambiente Empresarial (perfil `local`) - PADR√ÉO

Configurar as seguintes vari√°veis de ambiente apontando para os seus servidores:

```bash
# Configura√ß√£o do PostgreSQL
export DATASOURCE_URL="jdbc:postgresql://seu-postgres-empresarial:5432/suadb"
export DATASOURCE_USERNAME="seuusuario"
export DATASOURCE_PASSWORD="suasenha"

# Configura√ß√£o do Kafka
export KAFKA_BOOTSTRAP_SERVERS="seu-kafka-empresarial:9092"

# O perfil 'local' √© ativado automaticamente (padr√£o)
# Para explicitamente definir: export SPRING_PROFILES_ACTIVE="local"
```

#### Op√ß√£o B: Ambiente Local com Docker (perfil `docker`)

```bash
# Primeiro, iniciar o Docker Compose
docker-compose up -d
```

Isto inicia:
- **Kafka** (porta 9092) - modo KRaft, sem Zookeeper
- **PostgreSQL** (porta 5432) - banco de dados para ambas as aplica√ß√µes
- **Prometheus** (porta 9090) - coleta de m√©tricas
- **Grafana** (porta 3000) - visualiza√ß√£o de m√©tricas (admin/admin)

**Criar t√≥pico de snapshots (opcional, ser√° criado automaticamente):**
```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 \
  --create --topic task-snapshots --partitions 3 --replication-factor 1 \
  --config cleanup.policy=compact
```

**Para usar este perfil, defina:**
```bash
export SPRING_PROFILES_ACTIVE="docker"
```

#### Op√ß√£o C: Ambiente com Oracle Database (perfil `oracle`)

**1. Executar o script SQL de setup do Oracle:**
```sql
-- Execute o script em: producer-app/src/main/resources/oracle-outbox-setup.sql
-- Este script cria:
-- - Tabela OUTBOX_MESSAGES
-- - Sequence OUTBOX_SEQ
-- - √çndices de performance
-- - (Opcional) Oracle AQ queue para integra√ß√£o JMS
```

**2. Configurar vari√°veis de ambiente:**
```bash
# Configura√ß√£o do Oracle Database
export ORACLE_DATASOURCE_URL="jdbc:oracle:thin:@seu-oracle:1521:ORCL"
export ORACLE_DATASOURCE_USERNAME="seuusuario"
export ORACLE_DATASOURCE_PASSWORD="suasenha"

# Configura√ß√£o do Kafka
export KAFKA_BOOTSTRAP_SERVERS="seu-kafka-empresarial:9092"

# (Opcional) Configura√ß√£o do Oracle AQ
export ORACLE_AQ_QUEUE_NAME="OUTBOX_QUEUE"
export ORACLE_AQ_QUEUE_TABLE="OUTBOX_QUEUE_TABLE"
export ORACLE_AQ_POLL_INTERVAL_MS="1000"

# Ativar o perfil 'oracle'
export SPRING_PROFILES_ACTIVE="oracle"
```

**Notas sobre Oracle:**
- O outbox Oracle usa polling JDBC por padr√£o (similar ao PostgreSQL)
- Oracle AQ (Advanced Queuing) √© opcional e pode ser configurado para integra√ß√£o JMS
- A tabela de outbox usa CLOB para payloads grandes
- Limpeza autom√°tica de mensagens antigas pode ser configurada (ver SQL script)


### 2. Build do Projeto

```bash
mvn clean install
```

### 3. Executar Producer

#### Com perfil Empresarial `local` (padr√£o):
```bash
cd producer-app
# Assumindo que as vari√°veis de ambiente j√° est√£o configuradas (ver se√ß√£o 1)
mvn spring-boot:run
```

**Ou** com vari√°veis de ambiente inline:
```bash
cd producer-app
DATASOURCE_URL="jdbc:postgresql://seu-postgres:5432/suadb" \
DATASOURCE_USERNAME="seuusuario" \
DATASOURCE_PASSWORD="suasenha" \
KAFKA_BOOTSTRAP_SERVERS="seu-kafka:9092" \
mvn spring-boot:run
```

#### Com perfil Docker:
```bash
cd producer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=docker"
```

#### Com perfil Oracle:
```bash
cd producer-app
SPRING_PROFILES_ACTIVE=oracle \
ORACLE_DATASOURCE_URL="jdbc:oracle:thin:@seu-oracle:1521:ORCL" \
ORACLE_DATASOURCE_USERNAME="seuusuario" \
ORACLE_DATASOURCE_PASSWORD="suasenha" \
KAFKA_BOOTSTRAP_SERVERS="seu-kafka:9092" \
mvn spring-boot:run
```

O producer estar√° dispon√≠vel em http://localhost:8080

### 4. Executar Consumer(s)

#### Com perfil Empresarial `local` (padr√£o):

**Terminal 1 (Consumer 1):**
```bash
cd consumer-app
# Assumindo que as vari√°veis de ambiente j√° est√£o configuradas
mvn spring-boot:run
```

**Terminal 2 (Consumer 2 - opcional):**
```bash
cd consumer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--server.port=8082"
```

**Terminal 3 (Consumer 3 - opcional):**
```bash
cd consumer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--server.port=8083"
```

#### Com perfil Docker:

**Terminal 1 (Consumer 1):**
```bash
cd consumer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=docker"
```

**Terminal 2 (Consumer 2 - opcional):**
```bash
cd consumer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=docker --server.port=8082"
```

#### Com perfil Empresarial (vari√°veis inline):

```bash
cd consumer-app
DATASOURCE_URL="jdbc:postgresql://seu-postgres:5432/suadb" \
DATASOURCE_USERNAME="seuusuario" \
DATASOURCE_PASSWORD="suasenha" \
KAFKA_BOOTSTRAP_SERVERS="seu-kafka:9092" \
mvn spring-boot:run
```

## üèóÔ∏è Arquitetura para Alto Volume

### Cen√°rio: Milhares de Altera√ß√µes por Task

Quando uma task sofre muitas altera√ß√µes (ex: atualiza√ß√£o massiva de atributos), sem agrega√ß√£o cada altera√ß√£o geraria uma mensagem no Kafka, sobrecarregando o sistema e o frontend.

### Solu√ß√£o Implementada: Snapshot Aggregator

**Fluxo:**

```
[Producer] 
  ‚Üì insere outbox (atributo A mudou)
  ‚Üì insere outbox (atributo B mudou)
  ‚Üì insere outbox (atributo C mudou)
  ‚Üì
[OutboxAggregatorService] (scheduled 500ms)
  ‚Üì agrupa por task_id
  ‚Üì aplica debounce (200ms)
  ‚Üì merge: √∫ltima vers√£o de cada atributo
  ‚Üì publica 1 snapshot completo ‚Üí topic 'task-snapshots'
  ‚Üì marca mensagens originais como published
  ‚Üì
[TaskSnapshotConsumer]
  ‚Üì consome snapshot
  ‚Üì atualiza task_snapshots (read-model)
  ‚Üì frontend l√™ vers√£o completa
  ‚Üì (opcional) notifica frontend via WebSocket
```

### Configura√ß√£o para Alto D√©bito

**Produtor:**
- `aggregator-interval-ms: 500` - Frequ√™ncia de agrega√ß√£o
- `debounce-ms: 200` - Janela de espera antes de agregar
- Ajustar conforme volume (maior debounce = mais agrega√ß√£o, menor lat√™ncia)

**Consumidor de Snapshots:**
- Usar t√≥pico `task-snapshots` particionado por `taskId`
- Garantir ordena√ß√£o por task (partition key)
- Consumer group dedicado (`task-snapshot-consumer-group`)
- Escalar consumidores conforme parti√ß√µes

**Kafka:**
- Criar t√≥pico `task-snapshots` com n√∫mero adequado de parti√ß√µes
- Configurar `cleanup.policy=compact` para reter apenas √∫ltimo snapshot por key
- Monitorizar consumer lag

### Alternativas Consideradas

1. **Mensagens por atributo + marcador final**: 
   - ‚ùå Complexo de implementar (changeSetId, seqNo, isLast)
   - ‚ùå Frontend precisa reconstruir estado
   
2. **Kafka Streams para agrega√ß√£o**:
   - ‚úÖ Escal√°vel e robusto
   - ‚ùå Mais complexo de configurar e manter
   
3. **Snapshot no Produtor** (escolhido):
   - ‚úÖ Simples e eficaz
   - ‚úÖ Menos mensagens no Kafka
   - ‚úÖ Frontend consome estado completo
   - ‚ö†Ô∏è Debounce pode adicionar lat√™ncia (200ms)

## üîå Integra√ß√£o com Oracle Database

O projeto suporta Oracle Database como alternativa ao PostgreSQL para a tabela de outbox, ideal para ambientes empresariais que j√° utilizam Oracle e/ou Oracle AQ (Advanced Queuing).

### Abordagens de Integra√ß√£o

#### 1. **Polling JDBC** (Implementa√ß√£o Atual - Recomendada)

A abordagem mais simples e compat√≠vel com todos os ambientes Oracle:

```
[Aplica√ß√£o]
  ‚Üì insere transacionalmente em OUTBOX_MESSAGES (Oracle)
  ‚Üì
[OracleOutboxPollingService] (scheduled 1s)
  ‚Üì consulta: SELECT * FROM OUTBOX_MESSAGES WHERE PUBLISHED = 0
  ‚Üì publica mensagens no Kafka
  ‚Üì atualiza: UPDATE OUTBOX_MESSAGES SET PUBLISHED = 1
```

**Vantagens:**
- ‚úÖ Simples de implementar e manter
- ‚úÖ N√£o requer configura√ß√£o adicional do Oracle
- ‚úÖ Funciona com qualquer vers√£o do Oracle (12c+)
- ‚úÖ Transacional e confi√°vel

**Desvantagens:**
- ‚ö†Ô∏è Lat√™ncia de polling (configur√°vel, padr√£o 1s)
- ‚ö†Ô∏è Carga adicional no banco (queries peri√≥dicas)

#### 2. **Oracle AQ/JMS** (Dispon√≠vel - Opcional)

Abordagem baseada em mensageria nativa do Oracle, usando Oracle Advanced Queuing:

```
[Aplica√ß√£o]
  ‚Üì insere transacionalmente em OUTBOX_MESSAGES (Oracle)
  ‚Üì (trigger opcional) enfileira mensagem em AQ
  ‚Üì
[Oracle AQ Queue: OUTBOX_QUEUE]
  ‚Üì
[JMS Consumer] (na aplica√ß√£o)
  ‚Üì recebe notifica√ß√£o instant√¢nea da AQ
  ‚Üì publica no Kafka
  ‚Üì marca mensagem como publicada
```

**Vantagens:**
- ‚úÖ Lat√™ncia m√≠nima (notifica√ß√£o push)
- ‚úÖ Reduz carga de polling no banco
- ‚úÖ Integra√ß√£o nativa com Oracle

**Desvantagens:**
- ‚ùå Requer Oracle AQ configurado e licenciado
- ‚ùå Maior complexidade de setup
- ‚ùå Depend√™ncias adicionais (Oracle AQ libraries)

**Setup Oracle AQ:**
```sql
-- Ver script completo em: producer-app/src/main/resources/oracle-outbox-setup.sql
BEGIN
    DBMS_AQADM.CREATE_QUEUE_TABLE(...);
    DBMS_AQADM.CREATE_QUEUE(...);
    DBMS_AQADM.START_QUEUE(...);
END;
```

#### 3. **Debezium com Oracle Connector** (Alternativa Externa)

Usar Debezium para capturar mudan√ßas (CDC) na tabela de outbox Oracle:

```
[Oracle OUTBOX_MESSAGES]
  ‚Üì
[Debezium Oracle Connector] (via LogMiner ou XStream)
  ‚Üì captura INSERTs via CDC
  ‚Üì publica diretamente no Kafka
  ‚Üì
[Kafka Topic]
```

**Vantagens:**
- ‚úÖ Desacoplado da aplica√ß√£o
- ‚úÖ Baixa lat√™ncia
- ‚úÖ Escal√°vel

**Desvantagens:**
- ‚ùå Infraestrutura adicional (Kafka Connect)
- ‚ùå Requer permiss√µes especiais no Oracle (LogMiner/XStream)
- ‚ùå Mais complexo de configurar

### Escolha da Abordagem

**Recomenda√ß√£o:** Usar **Polling JDBC** (implementa√ß√£o atual) por padr√£o.

- Se lat√™ncia < 1s √© cr√≠tica: considerar **Oracle AQ/JMS**
- Se preferir desacoplar do c√≥digo: considerar **Debezium**

O projeto j√° implementa Polling JDBC e tem suporte b√°sico para Oracle AQ (estruturas criadas no SQL script).

## üìä Como Funciona

### Padr√£o Outbox (Producer)

1. Cliente faz POST para `/api/publish` ou `/api/publish-batch`
2. Mensagem √© **inserida na tabela `outbox_messages`** (transacional)
3. `OutboxPollingService` (agendado a cada 1s) l√™ mensagens n√£o publicadas
4. Publica no Kafka e marca como `published = true`
5. Usa `messageKey` para distribuir por parti√ß√µes

### Agrega√ß√£o de Outbox por Task (Snapshot Pattern)

Para lidar com alto volume de mensagens por task (ex: m√∫ltiplas altera√ß√µes de atributos), 
o sistema implementa um padr√£o de agrega√ß√£o:

1. **OutboxAggregatorService** (agendado a cada 500ms) agrupa mensagens outbox por `task_id`
2. Aplica uma janela de **debounce** (200ms por padr√£o) para aguardar mensagens relacionadas
3. **Merge** de atributos: √∫ltima altera√ß√£o de cada atributo prevalece
4. Publica um **snapshot completo** da task no t√≥pico `task-snapshots`
5. Marca mensagens originais como publicadas

**Benef√≠cios:**
- Reduz drasticamente o n√∫mero de mensagens enviadas ao Kafka
- Frontend consome apenas snapshots completos (simplifica l√≥gica)
- Mant√©m ordena√ß√£o por task (via partition key = taskId)
- Garante atomicidade (transacional)

### Consumer com Persist√™ncia

1. Recebe mensagem do Kafka (`@KafkaListener`)
2. Cria `MessageRecord` com `receivedAt` timestamp
3. **Simula processamento** (delay 2-20 segundos aleat√≥rio)
4. Tenta fazer parse como estrutura `Task` e persiste hierarquia
5. Atualiza `MessageRecord` com `processedAt` e `processingDurationMs`
6. **Commit manual** do offset apenas ap√≥s persist√™ncia bem-sucedida

### Consumer de Snapshots (Read-Model)

1. **TaskSnapshotConsumer** consome do t√≥pico `task-snapshots`
2. Atualiza tabela `task_snapshots` (read-model materializado)
3. Cada task tem um √∫nico registo com a vers√£o mais recente
4. Frontend consulta `task_snapshots` para obter estado completo
5. Notifica√ß√£o pode ser enviada via WebSocket ap√≥s atualiza√ß√£o (future work)

### Evitar Rebalances

Configura√ß√£o em `consumer-app/application.yml`:

```yaml
max.poll.interval.ms: 300000      # 5 minutos - tempo m√°ximo entre polls
session.timeout.ms: 60000          # 1 minuto - tempo de sess√£o
heartbeat.interval.ms: 20000       # 20 segundos - intervalo de heartbeat
max.poll.records: 1                # 1 mensagem por poll (controle fino)
```

## üß™ Testes de Integra√ß√£o

Execute os testes:

```bash
mvn test
```

Os testes usam:
- **Testcontainers** para PostgreSQL e Kafka
- **@EmbeddedKafka** para testes com Kafka
- **Awaitility** para assertions ass√≠ncronas

### Testes do Consumer

- Consumo de mensagem √∫nica
- M√∫ltiplas mensagens com keys diferentes
- Parsing de estrutura Task hier√°rquica
- Verifica√ß√£o de timestamps e dura√ß√£o

### Testes do Producer

- Publica√ß√£o via outbox pattern
- Distribui√ß√£o por parti√ß√µes
- M√∫ltiplas mensagens com diferentes clientes

## üì° Endpoints API

### Producer App (porta 8080)

#### Publicar mensagem √∫nica
```bash
curl -X POST http://localhost:8080/api/publish \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello Kafka!",
    "partitionKey": "client-1"
  }'
```

#### Publicar lote de mensagens
```bash
curl -X POST http://localhost:8080/api/publish-batch \
  -H "Content-Type: application/json" \
  -d '{
    "count": 30,
    "prefix": "TestMessage"
  }'
```

#### Estat√≠sticas do Outbox
```bash
curl http://localhost:8080/api/outbox/stats
```

#### Health check
```bash
curl http://localhost:8080/api/health
curl http://localhost:8080/actuator/health
```

### Consumer App (porta 8081+)

#### Parar consumo (graceful shutdown)
```bash
curl -X POST http://localhost:8081/internal/stop-consuming
```

#### M√©tricas Prometheus
```bash
curl http://localhost:8081/actuator/prometheus
```

## üìà Monitoriza√ß√£o

### Prometheus

Aceda a http://localhost:9090

Queries √∫teis:
```promql
# Taxa de mensagens processadas por segundo
rate(kafka_consumer_fetch_manager_records_consumed_total[1m])

# Dura√ß√£o m√©dia de processamento
avg(kafka_consumer_processing_duration_ms)

# Mensagens no outbox n√£o publicadas
outbox_messages_unpublished_total
```

### Grafana

1. Aceda a http://localhost:3000 (admin/admin)
2. O datasource Prometheus j√° est√° configurado
3. Crie dashboards personalizados ou importe templates

M√©tricas expostas:
- `outbox.messages.published` - Total de mensagens publicadas
- `outbox.messages.failed` - Total de falhas na publica√ß√£o
- M√©tricas padr√£o do Kafka (consumer lag, throughput, etc.)
- M√©tricas da aplica√ß√£o (JVM, CPU, mem√≥ria)

## üóÑÔ∏è Estrutura da Base de Dados

### Tabela: `tasks`
```sql
- id (bigserial)
- task_id (varchar, unique)
- raw_payload (text)
- created_at (timestamptz)
```

### Tabela: `task_attributes`
```sql
- id (bigserial)
- task_id (bigint FK)
- attribute_name (varchar)
- attribute_type (varchar) -- STRING, NUMERIC, DATE, BOOLEAN, ENTITY, TEXT
```

### Tabela: `task_attribute_values`
```sql
- id (bigserial)
- attribute_id (bigint FK)
- string_value (varchar)
- numeric_value (numeric)
- date_value (timestamptz)
- boolean_value (boolean)
- entity_ref (varchar)
- text_value (text)
```

### Tabela: `message_records`
```sql
- id (bigserial)
- raw_message (text)
- received_at (timestamptz)
- processed_at (timestamptz)
- kafka_topic (varchar)
- partition (integer)
- offset_value (bigint)
- message_key (varchar)
- processing_duration_ms (bigint)
```

### Tabela: `outbox_messages` (PostgreSQL)
```sql
- id (bigserial)
- payload (text)
- message_key (varchar)
- topic (varchar)
- published (boolean)
- created_at (timestamptz)
- published_at (timestamptz)
- client_id (varchar)
- task_id (varchar)          -- NEW: usado para agrega√ß√£o por task
```

### Tabela: `OUTBOX_MESSAGES` (Oracle)
```sql
- ID (NUMBER(19))            -- Primary key com OUTBOX_SEQ
- PAYLOAD (CLOB)             -- JSON payload
- MESSAGE_KEY (VARCHAR2(500))
- TOPIC (VARCHAR2(255))
- PUBLISHED (NUMBER(1))      -- 0=false, 1=true
- CREATED_AT (TIMESTAMP WITH TIME ZONE)
- PUBLISHED_AT (TIMESTAMP WITH TIME ZONE)
- CLIENT_ID (VARCHAR2(255))
- TASK_ID (VARCHAR2(255))    -- Usado para agrega√ß√£o por task
```

**Nota:** Para setup completo do Oracle, execute o script:
`producer-app/src/main/resources/oracle-outbox-setup.sql`

### Tabela: `task_snapshots`
```sql
- id (bigserial)
- task_id (varchar, unique)  -- Identificador √∫nico da task
- snapshot_data (text)       -- JSON completo do snapshot
- version (bigint)           -- Vers√£o do snapshot (incrementa a cada update)
- created_at (timestamptz)   -- Quando foi criado
- updated_at (timestamptz)   -- √öltima atualiza√ß√£o
- kafka_offset (bigint)      -- Offset do Kafka de origem
- kafka_partition (integer)  -- Parti√ß√£o do Kafka
```

## üé≠ Cen√°rios de Teste

### Teste 1: Distribui√ß√£o B√°sica
1. Iniciar 1 consumer
2. Publicar 30 mensagens: `POST /api/publish-batch` com `count: 30`
3. Observar que o consumer processa de todas as 3 parti√ß√µes
4. Verificar logs para ver dura√ß√£o de processamento (2-20s por mensagem)

### Teste 2: Rebalanceamento
1. Iniciar 1 consumer (porta 8081)
2. Publicar mensagens
3. Iniciar 2¬∫ consumer (porta 8082) ‚Üí observar rebalance nos logs
4. Publicar mais mensagens ‚Üí distribu√≠das entre consumers
5. Parar 2¬∫ consumer ‚Üí observar rebalance novamente

### Teste 3: Outbox Pattern em Tempo Real
1. Inserir mensagens diretamente na tabela outbox:
```sql
INSERT INTO outbox_messages (payload, message_key, topic, client_id, published, created_at)
VALUES ('Manual message', 'client-1', 'task-topic', 'client-1', false, NOW());
```
2. Observar mensagem ser publicada automaticamente (em 1s)
3. Verificar consumer processa a mensagem

### Teste 4: Processamento com Estrutura Task
```bash
curl -X POST http://localhost:8080/api/publish \
  -H "Content-Type: application/json" \
  -d '{
    "message": "{\"taskId\":\"TASK-001\",\"attributes\":[{\"name\":\"priority\",\"type\":\"STRING\",\"values\":[\"HIGH\"]},{\"name\":\"amount\",\"type\":\"NUMERIC\",\"values\":[\"1500.50\"]}]}",
    "partitionKey": "client-1"
  }'
```

Verificar na BD que a estrutura foi parseada e persistida:
```sql
SELECT t.task_id, ta.attribute_name, ta.attribute_type, 
       tav.string_value, tav.numeric_value
FROM tasks t
JOIN task_attributes ta ON ta.task_id = t.id
JOIN task_attribute_values tav ON tav.attribute_id = ta.id
WHERE t.task_id = 'TASK-001';
```

## üîß Configura√ß√µes Importantes

### Perfis de Execu√ß√£o

O sistema suporta tr√™s perfis atrav√©s da vari√°vel `SPRING_PROFILES_ACTIVE`:

- **`local`** (padr√£o): Usa Kafka e PostgreSQL externos via vari√°veis de ambiente (ambiente empresarial sem Docker)
- **`docker`**: Usa Kafka e PostgreSQL locais (localhost) via docker-compose
- **`oracle`**: Usa Oracle Database para outbox com Kafka externo via vari√°veis de ambiente

### Vari√°veis de Ambiente

#### Perfil `local` (PostgreSQL empresarial)

```bash
# PostgreSQL
DATASOURCE_URL=jdbc:postgresql://host:port/database
DATASOURCE_USERNAME=usuario
DATASOURCE_PASSWORD=senha

# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka-host:9092

# Perfil ativo (opcional, j√° √© o padr√£o)
SPRING_PROFILES_ACTIVE=local
```

#### Perfil `docker` (Docker local)

```bash
# N√£o requer vari√°veis de ambiente - usa valores hardcoded em application-docker.yml
# Para ativar:
SPRING_PROFILES_ACTIVE=docker
```

#### Perfil `oracle` (Oracle Database)

```bash
# Oracle Database
ORACLE_DATASOURCE_URL=jdbc:oracle:thin:@host:port:SID
ORACLE_DATASOURCE_USERNAME=usuario
ORACLE_DATASOURCE_PASSWORD=senha

# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka-host:9092

# Oracle AQ (opcional)
ORACLE_AQ_QUEUE_NAME=OUTBOX_QUEUE
ORACLE_AQ_QUEUE_TABLE=OUTBOX_QUEUE_TABLE
ORACLE_AQ_POLL_INTERVAL_MS=1000

# Perfil ativo
SPRING_PROFILES_ACTIVE=oracle
```

### Como Alternar Entre Perfis

**Op√ß√£o 1: Vari√°vel de ambiente**
```bash
export SPRING_PROFILES_ACTIVE=docker  # ou local, ou oracle
mvn spring-boot:run
```

**Op√ß√£o 2: Argumento da linha de comando**
```bash
mvn spring-boot:run -Dspring-boot.run.arguments="--spring.profiles.active=docker"
```

**Op√ß√£o 3: Propriedade do sistema**
```bash
mvn spring-boot:run -Dspring.profiles.active=docker
```

### Configura√ß√µes do Consumer (application.yml)

```yaml
spring.kafka.consumer:
  max-poll-records: 1                    # Processar 1 msg de cada vez
  properties:
    max.poll.interval.ms: 300000         # 5 min - ajuste conforme necess√°rio
    session.timeout.ms: 60000
    heartbeat.interval.ms: 20000

app.processing:
  min-delay-seconds: 2                   # Delay m√≠nimo (ajust√°vel)
  max-delay-seconds: 20                  # Delay m√°ximo (ajust√°vel)
```

### Configura√ß√µes do Producer (application.yml)

```yaml
app.outbox:
  poll-interval-ms: 1000                 # Poll a cada 1 segundo
  batch-size: 100                        # Processar at√© 100 msgs por vez
  aggregator-interval-ms: 500            # Intervalo do agregador
  debounce-ms: 200                       # Janela de debounce para agrega√ß√£o
  
app.kafka:
  topic: task-topic                      # T√≥pico principal
  snapshot-topic: task-snapshots         # T√≥pico de snapshots agregados
```

## üê≥ Deployment em Kubernetes

Exemplo de Deployment com graceful shutdown:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-consumer
spec:
  replicas: 3
  template:
    spec:
      terminationGracePeriodSeconds: 180
      containers:
      - name: consumer
        image: consumer-app:latest
        lifecycle:
          preStop:
            exec:
              command: 
              - /bin/sh
              - -c
              - "curl -X POST http://localhost:8081/internal/stop-consuming || true; sleep 10"
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
```

## üìö Tecnologias Utilizadas

- **Java 17**
- **Spring Boot 3.1.5**
- **Spring Kafka** (n√£o Spring Cloud Stream)
- **Hibernate 6.2.13** (Jakarta Persistence API)
- **PostgreSQL 15** (para perfil local/docker)
- **Oracle Database 12c+** (para perfil oracle - opcional)
- **Kafka 7.5.0** (modo KRaft, sem Zookeeper)
- **Prometheus + Grafana**
- **Testcontainers 1.19.1**
- **Maven**

## ü§î Troubleshooting

### Kafka n√£o arranca no Docker
```bash
docker-compose logs kafka
# Verificar se a porta 9092 est√° livre
# Recriar o volume se necess√°rio: docker-compose down -v
```

### Perfil n√£o est√° sendo aplicado corretamente
```bash
# Verificar qual perfil est√° ativo nos logs de inicializa√ß√£o:
# Procurar por: "The following profiles are active: local"

# For√ßar perfil espec√≠fico:
export SPRING_PROFILES_ACTIVE=docker  # ou local, ou oracle
mvn spring-boot:run

# Verificar configura√ß√£o carregada:
curl http://localhost:8080/actuator/env | jq '.propertySources'
```

### Oracle: Erro de conex√£o
```bash
# Verificar URL do JDBC:
# Formato thin: jdbc:oracle:thin:@hostname:port:SID
# Formato service: jdbc:oracle:thin:@hostname:port/service_name
# TNS: jdbc:oracle:thin:@(DESCRIPTION=(...))

# Testar conectividade:
telnet seu-oracle-host 1521

# Verificar se o usu√°rio tem permiss√µes:
# - SELECT, INSERT, UPDATE, DELETE em OUTBOX_MESSAGES
# - SELECT em OUTBOX_SEQ
# - (Opcional) EXECUTE em DBMS_AQ, DBMS_AQADM para Oracle AQ
```

### Oracle: Tabela OUTBOX_MESSAGES n√£o encontrada
```bash
# Executar o script de setup:
sqlplus usuario/senha@SID @producer-app/src/main/resources/oracle-outbox-setup.sql

# Verificar se a tabela foi criada:
sqlplus usuario/senha@SID
SQL> SELECT table_name FROM user_tables WHERE table_name = 'OUTBOX_MESSAGES';
SQL> SELECT sequence_name FROM user_sequences WHERE sequence_name = 'OUTBOX_SEQ';
```

### Oracle: Mensagens n√£o est√£o sendo publicadas
```bash
# Verificar mensagens pendentes no outbox:
sqlplus usuario/senha@SID
SQL> SELECT COUNT(*) FROM OUTBOX_MESSAGES WHERE PUBLISHED = 0;

# Verificar logs do producer:
# Procurar por: "Processing N unpublished messages from Oracle outbox"

# Verificar se o servi√ßo Oracle est√° ativo:
# Procurar por: "OracleOutboxPollingService" nos logs
# Se n√£o aparecer, verificar se app.outbox.use-oracle=true no perfil
```

### Rebalances frequentes
- Aumentar `max.poll.interval.ms` se mensagens demoram muito
- Reduzir `max-poll-records` para processar menos mensagens por vez
- Verificar se consumers est√£o a fazer commit regularmente

### Mensagens n√£o s√£o consumidas
```bash
# Verificar offset do consumer group
docker exec -it kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group task-consumer-group

# Verificar t√≥pico
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic task-topic
```

### Outbox messages n√£o s√£o publicadas
```sql
-- Verificar mensagens pendentes
SELECT * FROM outbox_messages WHERE published = false;

-- Verificar logs do producer
# Logs devem mostrar "Publishing message X to topic Y"
```

## üìÑ Licen√ßa

MIT License

## üë• Contribuidores

Desenvolvido como PoC para demonstrar:
- Kafka moderno sem Zookeeper
- Padr√£o Outbox transacional
- Preven√ß√£o de rebalances em processamento longo
- Monitoriza√ß√£o completa com Prometheus/Grafana
