# Kafka Partitions PoC - Modern Setup without Zookeeper

Este projeto demonstra uma aplicaÃ§Ã£o completa de Kafka usando Spring Kafka (sem Spring Cloud Stream), com persistÃªncia em PostgreSQL usando Hibernate 6, padrÃ£o Transactional Outbox, e monitorizaÃ§Ã£o com Prometheus e Grafana.

## ğŸ¯ CaracterÃ­sticas Principais

- âœ… **Kafka em modo KRaft** - Sem dependÃªncia de Zookeeper
- âœ… **PersistÃªncia completa** - PostgreSQL com Hibernate 6
- âœ… **PadrÃ£o Outbox** - ProduÃ§Ã£o transacional de mensagens
- âœ… **Hierarquia de dados** - Task â†’ TaskAttribute â†’ TaskAttributeValue
- âœ… **Processamento simulado** - Delay configurÃ¡vel (2-20 segundos)
- âœ… **PrevenÃ§Ã£o de rebalances** - ConfiguraÃ§Ãµes otimizadas para processamento longo
- âœ… **Graceful shutdown** - Endpoint para parar consumo antes de terminar o pod
- âœ… **MonitorizaÃ§Ã£o** - Prometheus + Grafana com mÃ©tricas personalizadas
- âœ… **Testes de integraÃ§Ã£o** - Testcontainers com Kafka e PostgreSQL
- âœ… **DistribuiÃ§Ã£o por partiÃ§Ãµes** - Mensagens distribuÃ­das por key (cliente)

## ğŸ“‹ Estrutura do Projeto

```
kafkaPartitionsPoc/
â”œâ”€â”€ consumer-app/          # AplicaÃ§Ã£o consumidora com persistÃªncia
â”‚   â”œâ”€â”€ entity/           # Task, TaskAttribute, TaskAttributeValue, MessageRecord
â”‚   â”œâ”€â”€ repository/       # Spring Data JPA repositories
â”‚   â”œâ”€â”€ service/          # TaskConsumerService com processamento 2-20s
â”‚   â”œâ”€â”€ config/           # Kafka consumer config com rebalance prevention
â”‚   â””â”€â”€ controller/       # Endpoint /internal/stop-consuming
â”œâ”€â”€ producer-app/          # AplicaÃ§Ã£o produtora com Outbox pattern
â”‚   â”œâ”€â”€ entity/           # OutboxMessage
â”‚   â”œâ”€â”€ repository/       # OutboxMessageRepository
â”‚   â”œâ”€â”€ service/          # OutboxPollingService (scheduler)
â”‚   â”œâ”€â”€ controller/       # REST API para adicionar mensagens ao outbox
â”‚   â””â”€â”€ config/           # Kafka producer config
â”œâ”€â”€ monitoring/            # ConfiguraÃ§Ãµes Prometheus + Grafana
â””â”€â”€ docker-compose.yml     # Kafka (KRaft), PostgreSQL, Prometheus, Grafana
```

## âš™ï¸ ConfiguraÃ§Ã£o de Ambientes

Este projeto suporta dois ambientes de execuÃ§Ã£o. Para instruÃ§Ãµes detalhadas, consulte [CONFIGURACAO_AMBIENTES.md](CONFIGURACAO_AMBIENTES.md).

### ğŸ¢ Ambiente Empresarial (Perfil `local`)
Para usar Kafka e PostgreSQL externos (sem Docker local):

1. **Editar configuraÃ§Ã£o**: Abra `application-local.yaml` em ambas as aplicaÃ§Ãµes (producer-app e consumer-app) e configure:
   - `spring.datasource.url`: URL do PostgreSQL empresarial
   - `spring.datasource.username`: Utilizador da BD
   - `spring.datasource.password`: Password da BD
   - `spring.kafka.bootstrap-servers`: EndereÃ§o do Kafka empresarial

2. **Executar com perfil local**:
   ```bash
   # Producer
   cd producer-app
   mvn spring-boot:run -Dspring-boot.run.profiles=local
   
   # Consumer
   cd consumer-app
   mvn spring-boot:run -Dspring-boot.run.profiles=local
   ```

### ğŸ³ Ambiente Docker Local (Perfil `docker` - padrÃ£o)
Para usar Kafka e PostgreSQL em containers Docker:

1. **Iniciar infraestrutura**:
   ```bash
   docker-compose up -d
   ```

2. **Executar aplicaÃ§Ãµes**:
   ```bash
   cd producer-app && mvn spring-boot:run
   cd consumer-app && mvn spring-boot:run
   ```

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Java 17+
- Maven 3.6+
- Docker e Docker Compose (apenas para ambiente Docker)

### 1. Iniciar Infraestrutura (Apenas para Ambiente Docker)

```bash
docker-compose up -d
```

Isto inicia:
- **Kafka** (porta 9092) - modo KRaft, sem Zookeeper
- **PostgreSQL** (porta 5432) - banco de dados para ambas as aplicaÃ§Ãµes
- **Prometheus** (porta 9090) - coleta de mÃ©tricas
- **Grafana** (porta 3000) - visualizaÃ§Ã£o de mÃ©tricas (admin/admin)

### 2. Build do Projeto

```bash
mvn clean install
```

### 3. Executar Producer

```bash
cd producer-app
mvn spring-boot:run
```

O producer estarÃ¡ disponÃ­vel em http://localhost:8080

### 4. Executar Consumer(s)

**Terminal 1 (Consumer 1):**
```bash
cd consumer-app
mvn spring-boot:run
```

**Terminal 2 (Consumer 2 - opcional):**
```bash
cd consumer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--server.port=8082"
```

**Terminal 3 (Consumer 3 - opcional):**
```bash
cd consumer-app
mvn spring-boot:run -Dspring-boot.run.arguments="--server.port=8083"
```

## ğŸ“Š Como Funciona

### PadrÃ£o Outbox (Producer)

1. Cliente faz POST para `/api/publish` ou `/api/publish-batch`
2. Mensagem Ã© **inserida na tabela `outbox_messages`** (transacional)
3. `OutboxPollingService` (agendado a cada 1s) lÃª mensagens nÃ£o publicadas
4. Publica no Kafka e marca como `published = true`
5. Usa `messageKey` para distribuir por partiÃ§Ãµes

### Consumer com PersistÃªncia

1. Recebe mensagem do Kafka (`@KafkaListener`)
2. Cria `MessageRecord` com `receivedAt` timestamp
3. **Simula processamento** (delay 2-20 segundos aleatÃ³rio)
4. Tenta fazer parse como estrutura `Task` e persiste hierarquia
5. Atualiza `MessageRecord` com `processedAt` e `processingDurationMs`
6. **Commit manual** do offset apenas apÃ³s persistÃªncia bem-sucedida

### Evitar Rebalances

ConfiguraÃ§Ã£o em `consumer-app/application.yml`:

```yaml
max.poll.interval.ms: 300000      # 5 minutos - tempo mÃ¡ximo entre polls
session.timeout.ms: 60000          # 1 minuto - tempo de sessÃ£o
heartbeat.interval.ms: 20000       # 20 segundos - intervalo de heartbeat
max.poll.records: 1                # 1 mensagem por poll (controle fino)
```

## ğŸ§ª Testes de IntegraÃ§Ã£o

Execute os testes:

```bash
mvn test
```

Os testes usam:
- **Testcontainers** para PostgreSQL e Kafka
- **@EmbeddedKafka** para testes com Kafka
- **Awaitility** para assertions assÃ­ncronas

### Testes do Consumer

- Consumo de mensagem Ãºnica
- MÃºltiplas mensagens com keys diferentes
- Parsing de estrutura Task hierÃ¡rquica
- VerificaÃ§Ã£o de timestamps e duraÃ§Ã£o

### Testes do Producer

- PublicaÃ§Ã£o via outbox pattern
- DistribuiÃ§Ã£o por partiÃ§Ãµes
- MÃºltiplas mensagens com diferentes clientes

## ğŸ“¡ Endpoints API

### Producer App (porta 8080)

#### Publicar mensagem Ãºnica
```bash
curl -X POST http://localhost:8080/api/publish \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello Kafka!",
    "partitionKey": "client-1"
  }'
```

#### Publicar lote de mensagens
```bash
curl -X POST http://localhost:8080/api/publish-batch \
  -H "Content-Type: application/json" \
  -d '{
    "count": 30,
    "prefix": "TestMessage"
  }'
```

#### EstatÃ­sticas do Outbox
```bash
curl http://localhost:8080/api/outbox/stats
```

#### Health check
```bash
curl http://localhost:8080/api/health
curl http://localhost:8080/actuator/health
```

### Consumer App (porta 8081+)

#### Parar consumo (graceful shutdown)
```bash
curl -X POST http://localhost:8081/internal/stop-consuming
```

#### MÃ©tricas Prometheus
```bash
curl http://localhost:8081/actuator/prometheus
```

## ğŸ“ˆ MonitorizaÃ§Ã£o

### Prometheus

Aceda a http://localhost:9090

Queries Ãºteis:
```promql
# Taxa de mensagens processadas por segundo
rate(kafka_consumer_fetch_manager_records_consumed_total[1m])

# DuraÃ§Ã£o mÃ©dia de processamento
avg(kafka_consumer_processing_duration_ms)

# Mensagens no outbox nÃ£o publicadas
outbox_messages_unpublished_total
```

### Grafana

1. Aceda a http://localhost:3000 (admin/admin)
2. O datasource Prometheus jÃ¡ estÃ¡ configurado
3. Crie dashboards personalizados ou importe templates

MÃ©tricas expostas:
- `outbox.messages.published` - Total de mensagens publicadas
- `outbox.messages.failed` - Total de falhas na publicaÃ§Ã£o
- MÃ©tricas padrÃ£o do Kafka (consumer lag, throughput, etc.)
- MÃ©tricas da aplicaÃ§Ã£o (JVM, CPU, memÃ³ria)

## ğŸ—„ï¸ Estrutura da Base de Dados

### Tabela: `tasks`
```sql
- id (bigserial)
- task_id (varchar, unique)
- raw_payload (text)
- created_at (timestamptz)
```

### Tabela: `task_attributes`
```sql
- id (bigserial)
- task_id (bigint FK)
- attribute_name (varchar)
- attribute_type (varchar) -- STRING, NUMERIC, DATE, BOOLEAN, ENTITY, TEXT
```

### Tabela: `task_attribute_values`
```sql
- id (bigserial)
- attribute_id (bigint FK)
- string_value (varchar)
- numeric_value (numeric)
- date_value (timestamptz)
- boolean_value (boolean)
- entity_ref (varchar)
- text_value (text)
```

### Tabela: `message_records`
```sql
- id (bigserial)
- raw_message (text)
- received_at (timestamptz)
- processed_at (timestamptz)
- kafka_topic (varchar)
- partition (integer)
- offset_value (bigint)
- message_key (varchar)
- processing_duration_ms (bigint)
```

### Tabela: `outbox_messages`
```sql
- id (bigserial)
- payload (text)
- message_key (varchar)
- topic (varchar)
- published (boolean)
- created_at (timestamptz)
- published_at (timestamptz)
- client_id (varchar)
```

## ğŸ­ CenÃ¡rios de Teste

### Teste 1: DistribuiÃ§Ã£o BÃ¡sica
1. Iniciar 1 consumer
2. Publicar 30 mensagens: `POST /api/publish-batch` com `count: 30`
3. Observar que o consumer processa de todas as 3 partiÃ§Ãµes
4. Verificar logs para ver duraÃ§Ã£o de processamento (2-20s por mensagem)

### Teste 2: Rebalanceamento
1. Iniciar 1 consumer (porta 8081)
2. Publicar mensagens
3. Iniciar 2Âº consumer (porta 8082) â†’ observar rebalance nos logs
4. Publicar mais mensagens â†’ distribuÃ­das entre consumers
5. Parar 2Âº consumer â†’ observar rebalance novamente

### Teste 3: Outbox Pattern em Tempo Real
1. Inserir mensagens diretamente na tabela outbox:
```sql
INSERT INTO outbox_messages (payload, message_key, topic, client_id, published, created_at)
VALUES ('Manual message', 'client-1', 'task-topic', 'client-1', false, NOW());
```
2. Observar mensagem ser publicada automaticamente (em 1s)
3. Verificar consumer processa a mensagem

### Teste 4: Processamento com Estrutura Task
```bash
curl -X POST http://localhost:8080/api/publish \
  -H "Content-Type: application/json" \
  -d '{
    "message": "{\"taskId\":\"TASK-001\",\"attributes\":[{\"name\":\"priority\",\"type\":\"STRING\",\"values\":[\"HIGH\"]},{\"name\":\"amount\",\"type\":\"NUMERIC\",\"values\":[\"1500.50\"]}]}",
    "partitionKey": "client-1"
  }'
```

Verificar na BD que a estrutura foi parseada e persistida:
```sql
SELECT t.task_id, ta.attribute_name, ta.attribute_type, 
       tav.string_value, tav.numeric_value
FROM tasks t
JOIN task_attributes ta ON ta.task_id = t.id
JOIN task_attribute_values tav ON tav.attribute_id = ta.id
WHERE t.task_id = 'TASK-001';
```

## ğŸ”§ ConfiguraÃ§Ãµes Importantes

### ConfiguraÃ§Ãµes do Consumer (application.yml)

```yaml
spring.kafka.consumer:
  max-poll-records: 1                    # Processar 1 msg de cada vez
  properties:
    max.poll.interval.ms: 300000         # 5 min - ajuste conforme necessÃ¡rio
    session.timeout.ms: 60000
    heartbeat.interval.ms: 20000

app.processing:
  min-delay-seconds: 2                   # Delay mÃ­nimo (ajustÃ¡vel)
  max-delay-seconds: 20                  # Delay mÃ¡ximo (ajustÃ¡vel)
```

### ConfiguraÃ§Ãµes do Producer (application.yml)

```yaml
app.outbox:
  poll-interval-ms: 1000                 # Poll a cada 1 segundo
  batch-size: 100                        # Processar atÃ© 100 msgs por vez
```

## ğŸ³ Deployment em Kubernetes

Exemplo de Deployment com graceful shutdown:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-consumer
spec:
  replicas: 3
  template:
    spec:
      terminationGracePeriodSeconds: 180
      containers:
      - name: consumer
        image: consumer-app:latest
        lifecycle:
          preStop:
            exec:
              command: 
              - /bin/sh
              - -c
              - "curl -X POST http://localhost:8081/internal/stop-consuming || true; sleep 10"
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
```

## ğŸ“š Tecnologias Utilizadas

- **Java 17**
- **Spring Boot 3.1.5**
- **Spring Kafka** (nÃ£o Spring Cloud Stream)
- **Hibernate 6.2.13** (Jakarta Persistence API)
- **PostgreSQL 15**
- **Kafka 7.5.0** (modo KRaft, sem Zookeeper)
- **Prometheus + Grafana**
- **Testcontainers 1.19.1**
- **Maven**

## ğŸ¤” Troubleshooting

### Kafka nÃ£o arranca no Docker
```bash
docker-compose logs kafka
# Verificar se a porta 9092 estÃ¡ livre
# Recriar o volume se necessÃ¡rio: docker-compose down -v
```

### Rebalances frequentes
- Aumentar `max.poll.interval.ms` se mensagens demoram muito
- Reduzir `max-poll-records` para processar menos mensagens por vez
- Verificar se consumers estÃ£o a fazer commit regularmente

### Mensagens nÃ£o sÃ£o consumidas
```bash
# Verificar offset do consumer group
docker exec -it kafka kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group task-consumer-group

# Verificar tÃ³pico
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic task-topic
```

### Outbox messages nÃ£o sÃ£o publicadas
```sql
-- Verificar mensagens pendentes
SELECT * FROM outbox_messages WHERE published = false;

-- Verificar logs do producer
# Logs devem mostrar "Publishing message X to topic Y"
```

## ğŸ“„ LicenÃ§a

MIT License

## ğŸ‘¥ Contribuidores

Desenvolvido como PoC para demonstrar:
- Kafka moderno sem Zookeeper
- PadrÃ£o Outbox transacional
- PrevenÃ§Ã£o de rebalances em processamento longo
- MonitorizaÃ§Ã£o completa com Prometheus/Grafana
